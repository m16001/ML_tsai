{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 這一段可以選擇是否執行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-05-15T09:52:20.382601Z",
          "iopub.status.busy": "2025-05-15T09:52:20.382011Z",
          "iopub.status.idle": "2025-05-15T09:52:20.649593Z",
          "shell.execute_reply": "2025-05-15T09:52:20.648999Z",
          "shell.execute_reply.started": "2025-05-15T09:52:20.382577Z"
        },
        "id": "edemwgmSKBkz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-03T16:00:09.563834Z",
          "iopub.status.busy": "2025-06-03T16:00:09.563595Z",
          "iopub.status.idle": "2025-06-03T16:00:09.787723Z",
          "shell.execute_reply": "2025-06-03T16:00:09.786778Z",
          "shell.execute_reply.started": "2025-06-03T16:00:09.563810Z"
        },
        "id": "-OLqC9u1KBk0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-05-15T09:52:20.872044Z",
          "iopub.status.busy": "2025-05-15T09:52:20.871812Z",
          "iopub.status.idle": "2025-05-15T09:52:34.187589Z",
          "shell.execute_reply": "2025-05-15T09:52:34.186903Z",
          "shell.execute_reply.started": "2025-05-15T09:52:20.872024Z"
        },
        "id": "29irZT_WKBk0",
        "outputId": "82f0df2b-b829-40ed-9f50-58ded3959b33",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "!wget -O food11.zip https://www.dropbox.com/s/up5q1gthsz3v0dq/food-11.zip?dl=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-05-15T09:52:34.190041Z",
          "iopub.status.busy": "2025-05-15T09:52:34.189797Z",
          "iopub.status.idle": "2025-05-15T09:52:45.230149Z",
          "shell.execute_reply": "2025-05-15T09:52:45.229478Z",
          "shell.execute_reply.started": "2025-05-15T09:52:34.190022Z"
        },
        "id": "Ko8mSCmTKBk1",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "8db3c07b-8a1c-4da2-e181-c38ea246cae6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "! unzip food11.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-03T16:00:21.856900Z",
          "iopub.status.busy": "2025-06-03T16:00:21.856343Z",
          "iopub.status.idle": "2025-06-03T16:00:21.860563Z",
          "shell.execute_reply": "2025-06-03T16:00:21.859812Z",
          "shell.execute_reply.started": "2025-06-03T16:00:21.856870Z"
        },
        "id": "xj2eE64OKBk1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "_exp_name = \"sample\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntHLdnl0KBk1"
      },
      "source": [
        "# import package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-03T16:00:27.315009Z",
          "iopub.status.busy": "2025-06-03T16:00:27.314468Z",
          "iopub.status.idle": "2025-06-03T16:00:40.356482Z",
          "shell.execute_reply": "2025-06-03T16:00:40.355922Z",
          "shell.execute_reply.started": "2025-06-03T16:00:27.314987Z"
        },
        "id": "hC6Vzq5eKBk3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-03T16:00:44.282275Z",
          "iopub.status.busy": "2025-06-03T16:00:44.281655Z",
          "iopub.status.idle": "2025-06-03T16:00:44.384666Z",
          "shell.execute_reply": "2025-06-03T16:00:44.384162Z",
          "shell.execute_reply.started": "2025-06-03T16:00:44.282243Z"
        },
        "id": "Th4uphHNKBk3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "myseed = 6666  # set a random seed for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(myseed)\n",
        "torch.manual_seed(myseed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(myseed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jskBu-UyKBk3"
      },
      "source": [
        "# transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-03T16:00:49.100807Z",
          "iopub.status.busy": "2025-06-03T16:00:49.100506Z",
          "iopub.status.idle": "2025-06-03T16:00:49.106583Z",
          "shell.execute_reply": "2025-06-03T16:00:49.105873Z",
          "shell.execute_reply.started": "2025-06-03T16:00:49.100785Z"
        },
        "id": "avOrS282KBk4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_tfm = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_tfm = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
        "    transforms.TrivialAugmentWide(),  \n",
        "    # transforms.RandomRotation(15),\n",
        "    # transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcZ_nCHeKBk5"
      },
      "source": [
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-03T16:01:02.761273Z",
          "iopub.status.busy": "2025-06-03T16:01:02.760975Z",
          "iopub.status.idle": "2025-06-03T16:01:02.768340Z",
          "shell.execute_reply": "2025-06-03T16:01:02.767362Z",
          "shell.execute_reply.started": "2025-06-03T16:01:02.761250Z"
        },
        "id": "Y6B_Zyj0Xoq-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes=11):\n",
        "        super(Classifier, self).__init__()\n",
        "\n",
        "        \n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "\n",
        "        \n",
        "        for param in list(self.resnet.parameters())[-6:]:\n",
        "            param.requires_grad = True\n",
        "\n",
        "        in_features = self.resnet.fc.in_features\n",
        "        '''\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Dropout(0.4),  # Dropout保持原樣0.5→→→改0.4\n",
        "            nn.BatchNorm1d(in_features),  # 添加 BatchNorm\n",
        "            nn.Linear(in_features, num_classes)\n",
        "        )\n",
        "        '''\n",
        "        self.resnet.fc = nn.Sequential(\n",
        "            nn.Dropout(0.4),                # ← ① 第一個 Dropout（輸入層前）\n",
        "            nn.BatchNorm1d(in_features),   # ← ② 第一個 BN（對原特徵進行標準化）\n",
        "            nn.Linear(in_features, 512),   # ← 線性變換\n",
        "            nn.ReLU(),                     # ← 非線性激活\n",
        "            nn.BatchNorm1d(512),           # ← ③ 第二個 BN（對隱藏層標準化）\n",
        "            nn.Dropout(0.3),               # ← ④ 第二個 Dropout（隱藏層後防過擬合）\n",
        "            nn.Linear(512, num_classes)    # ← 輸出層\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7FmQ6ndKBk5"
      },
      "source": [
        "# configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-03T16:01:07.938665Z",
          "iopub.status.busy": "2025-06-03T16:01:07.938349Z",
          "iopub.status.idle": "2025-06-03T16:01:09.413822Z",
          "shell.execute_reply": "2025-06-03T16:01:09.412982Z",
          "shell.execute_reply.started": "2025-06-03T16:01:07.938643Z"
        },
        "id": "pcX9vD7iKBk5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# \"cuda\" only when GPUs are available.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Initialize a model, and put it on the device specified.\n",
        "model = Classifier(num_classes=11).to(device)\n",
        "\n",
        "# The number of batch size.\n",
        "batch_size = 64\n",
        "\n",
        "# The number of training epochs.\n",
        "n_epochs = 36  \n",
        "patience = 7  # Early stopping patience\n",
        "\n",
        "learning_rate = 3e-5  # 进一步降低学习率1e-3→→→5e-4→→→1e-4→→→5e-5→→→3e-5（配合adamw）\n",
        "\n",
        "# 添加更强的权重衰减（L2正则化）\n",
        "weight_decay = 3e-3  # 增加权重衰减系数1e-3→→→3e-3→→→5e-3（配合adamw）\n",
        "# Optimizer and Scheduler\n",
        "optimizer = torch.optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),  # 只优化可训练参数\n",
        "    lr=learning_rate,\n",
        "    weight_decay=weight_decay  # 应用L2正则化\n",
        ")\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs, eta_min=1e-6)\n",
        "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex19rMzh747S"
      },
      "source": [
        "# 自動略過壞圖 dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-03T16:01:42.523429Z",
          "iopub.status.busy": "2025-06-03T16:01:42.522706Z",
          "iopub.status.idle": "2025-06-03T16:05:06.583414Z",
          "shell.execute_reply": "2025-06-03T16:05:06.582621Z",
          "shell.execute_reply.started": "2025-06-03T16:01:42.523376Z"
        },
        "id": "r-8KdV2X747S",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# for kaggle\n",
        "class FoodDataset(Dataset):\n",
        "    def __init__(self, path, tfm=None, files=None):\n",
        "        super(FoodDataset, self).__init__()\n",
        "        self.path = path\n",
        "        self.transform = tfm\n",
        "\n",
        "        # === ✅ 更改：考慮大小寫副檔名 .JPG / .jpeg 等\n",
        "        all_files = sorted([\n",
        "            os.path.join(path, x)\n",
        "            for x in os.listdir(path)\n",
        "            if x.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
        "        ])\n",
        "        if files is not None:\n",
        "            all_files = files\n",
        "\n",
        "        # === ✅ 新增：過濾掉無法正常開啟的圖片\n",
        "        self.files = []\n",
        "        for f in all_files:\n",
        "            try:\n",
        "                with Image.open(f) as img:\n",
        "                    img.verify()  # 驗證圖像\n",
        "                self.files.append(f)\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ 略過壞圖: {f} ({e})\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fname = self.files[idx]\n",
        "\n",
        "        # === ✅ 新增：錯誤保護，防止 Image.open() 崩潰（Colab有時I/O異常）\n",
        "        try:\n",
        "            im = Image.open(fname).convert(\"RGB\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ 無法開啟圖像 {fname}: {e}，使用黑圖代替\")\n",
        "            im = Image.new(\"RGB\", (224, 224), color=(0, 0, 0))  # 回傳黑圖，避免崩潰\n",
        "\n",
        "        if self.transform:\n",
        "            im = self.transform(im)\n",
        "\n",
        "        # 讀取 label\n",
        "        try:\n",
        "            filename = fname.replace(\"\\\\\", \"/\").split(\"/\")[-1]\n",
        "            label = int(filename.split(\"_\")[0])\n",
        "        except:\n",
        "            label = -1  # 用於 test/test_no_label 時\n",
        "\n",
        "        return im, label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_set = FoodDataset(\"./train\", tfm=train_tfm)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
        "\n",
        "valid_set = FoodDataset(\"./valid\", tfm=test_tfm)\n",
        "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "test_set = FoodDataset(\"./test\", tfm=test_tfm)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ9289cfKBk6"
      },
      "source": [
        "# start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-06-03T16:07:55.984994Z",
          "iopub.status.busy": "2025-06-03T16:07:55.984196Z",
          "iopub.status.idle": "2025-06-03T18:36:37.078706Z",
          "shell.execute_reply": "2025-06-03T18:36:37.077967Z",
          "shell.execute_reply.started": "2025-06-03T16:07:55.984967Z"
        },
        "id": "EZqumjYCKBk7",
        "outputId": "ce8063be-f165-4d63-f6c5-ecd2f4a00743",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "'''\n",
        "try:\n",
        "    model.load_state_dict(torch.load(\"/kaggle/input/r50ckpt/best_model.ckpt\"))\n",
        "    print(\"成功載入 best_model.ckpt 權重，從中斷處繼續訓練。\")\n",
        "    # ... (註解部分可自行決定是否依需求處理 best_acc)\n",
        "except FileNotFoundError:\n",
        "    print(\"best_model.ckpt 檔案不存在，將從頭開始訓練。\")\n",
        "except Exception as e:\n",
        "    print(f\"載入權重時發生錯誤: {e}，將從頭開始訓練。\")\n",
        "'''\n",
        "# 创建记录训练过程的列表\n",
        "# 创建记录训练过程的列表\n",
        "train_losses = []\n",
        "train_accs = []\n",
        "valid_losses = []\n",
        "valid_accs = []\n",
        "\n",
        "stale = 0\n",
        "best_acc = 0\n",
        "for epoch in range(n_epochs):\n",
        "    # 训练模式\n",
        "    model.train()\n",
        "    train_loss = []\n",
        "    train_accs_epoch = []\n",
        "    for batch in tqdm(train_loader):\n",
        "        imgs, labels = batch\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "# === 新增開始：Mixup 實作 ===\n",
        "        # Mixup 超參數\n",
        "        mixup_alpha = 0.4  # 可調整\n",
        "        lam = np.random.beta(mixup_alpha, mixup_alpha)\n",
        "        index = torch.randperm(imgs.size(0)).to(device)\n",
        "\n",
        "        mixed_imgs = lam * imgs + (1 - lam) * imgs[index]\n",
        "        labels_a, labels_b = labels, labels[index]\n",
        "# === 新增結束 ===\n",
        "\n",
        "        #因mixup修改logits以及loss\n",
        "        #logits = model(imgs)\n",
        "        #loss = criterion(logits, labels)\n",
        "# === 修改：forward 與 loss 計算 ===\n",
        "        logits = model(mixed_imgs)\n",
        "        loss = lam * criterion(logits, labels_a) + (1 - lam) * criterion(logits, labels_b)\n",
        "# === 修改結束 ===\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
        "        train_loss.append(loss.item())\n",
        "        train_accs_epoch.append(acc.item())\n",
        "\n",
        "    train_loss_avg = sum(train_loss) / len(train_loss)\n",
        "    train_acc_avg = sum(train_accs_epoch) / len(train_accs_epoch)\n",
        "\n",
        "    # 验证模式\n",
        "    model.eval()\n",
        "    valid_loss = []\n",
        "    valid_accs_epoch = []\n",
        "    for batch in tqdm(valid_loader):\n",
        "        imgs, labels = batch\n",
        "        imgs = imgs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(imgs)\n",
        "\n",
        "        loss = criterion(logits, labels)\n",
        "        acc = (logits.argmax(dim=-1) == labels).float().mean()\n",
        "\n",
        "        valid_loss.append(loss.item())\n",
        "        valid_accs_epoch.append(acc.item())\n",
        "\n",
        "    valid_loss_avg = sum(valid_loss) / len(valid_loss)\n",
        "    valid_acc_avg = sum(valid_accs_epoch) / len(valid_accs_epoch)\n",
        "\n",
        "    # 更新学习率调度器\n",
        "    scheduler.step()\n",
        "    #scheduler.step(valid_acc_avg)  #for ReduceLROnPlateau\n",
        "\n",
        "    # 记录这个 epoch 的指标（新增部分）\n",
        "    train_losses.append(train_loss_avg)\n",
        "    train_accs.append(train_acc_avg)\n",
        "    valid_losses.append(valid_loss_avg)\n",
        "    valid_accs.append(valid_acc_avg)\n",
        "\n",
        "    # 打印训练信息，包括当前学习率\n",
        "    #current_lr = scheduler.get_last_lr()[0] #改用ReduceLROnPlateau所以先註解\n",
        "    current_lr = optimizer.param_groups[0]['lr'] #改用ReduceLROnPlateau\n",
        "    print(f\"Epoch {epoch+1}/{n_epochs}, Train Acc: {train_acc_avg:.4f}, Valid Acc: {valid_acc_avg:.4f}, Train Loss: {train_loss_avg:.4f}, Valid Loss: {valid_loss_avg:.4f}, LR: {current_lr:.6f}\")\n",
        "\n",
        "    # 保存最佳模型\n",
        "    if valid_acc_avg > best_acc:\n",
        "        best_acc = valid_acc_avg\n",
        "        torch.save(model.state_dict(), \"best_model.ckpt\")\n",
        "        print(\"  <-- Best model updated!\")  # 顯示提示訊息\n",
        "        stale = 0\n",
        "    else:\n",
        "        stale += 1\n",
        "        if stale > patience:  # 调整 patience 为 5→→→使用ReduceLROnPlateau 調整為7\n",
        "            #（因為ReduceLROnPlateau 也有使用patience）\n",
        "            print(f\"No improvement for {stale} epochs, early stopping\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWZ1vZwIKBk7"
      },
      "source": [
        "# 繪製loss acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "execution": {
          "iopub.execute_input": "2025-06-03T19:08:36.723993Z",
          "iopub.status.busy": "2025-06-03T19:08:36.723299Z",
          "iopub.status.idle": "2025-06-03T19:08:37.490885Z",
          "shell.execute_reply": "2025-06-03T19:08:37.490198Z",
          "shell.execute_reply.started": "2025-06-03T19:08:36.723970Z"
        },
        "id": "W6p_-9yqKBk7",
        "outputId": "5c1c4227-ef0d-4a22-ae8f-9050e04bb962",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 绘制训练过程图\n",
        "plt.figure(figsize=(10, 6))\n",
        "epochs = np.arange(1, len(train_losses) + 1)\n",
        "\n",
        "plt.plot(epochs, train_losses, 'r-', label='train_loss')\n",
        "plt.plot(epochs, valid_losses, 'b-', label='val_loss')\n",
        "plt.plot(epochs, train_accs, 'g-', label='train_acc')\n",
        "plt.plot(epochs, valid_accs, 'k-', label='val_acc')\n",
        "\n",
        "plt.title('Training Loss and Accuracy W/OUT Learning Rate Decay')\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('Loss/Accuracy')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "\n",
        "# 设置 y 轴范围，使图像更接近示例\n",
        "plt.ylim(0, 1.8)\n",
        "\n",
        "# 保存图像\n",
        "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5suhNhx0KBk7"
      },
      "source": [
        "# Testing and generate prediction CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-06-03T19:08:55.135686Z",
          "iopub.status.busy": "2025-06-03T19:08:55.135136Z",
          "iopub.status.idle": "2025-06-03T19:09:26.770642Z",
          "shell.execute_reply": "2025-06-03T19:09:26.769874Z",
          "shell.execute_reply.started": "2025-06-03T19:08:55.135659Z"
        },
        "id": "eqGXE_T2KBk7",
        "outputId": "a76621f9-dbab-4539-e4c6-1bc617af6e7d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 94/94 [00:25<00:00,  3.75it/s]\n"
          ]
        }
      ],
      "source": [
        "model_best = Classifier().to(device)\n",
        "model_best.load_state_dict(torch.load(\"best_model.ckpt\"))#移掉/kaggle/working/，等回kaggle再用\n",
        "# model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n",
        "model_best.eval()\n",
        "prediction = []\n",
        "with torch.no_grad():\n",
        "    for data,_ in tqdm(test_loader):\n",
        "        test_pred = model_best(data.to(device))\n",
        "        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
        "        prediction += test_label.squeeze().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-06-03T19:10:19.746741Z",
          "iopub.status.busy": "2025-06-03T19:10:19.746445Z",
          "iopub.status.idle": "2025-06-03T19:10:19.758871Z",
          "shell.execute_reply": "2025-06-03T19:10:19.758296Z",
          "shell.execute_reply.started": "2025-06-03T19:10:19.746708Z"
        },
        "id": "jVWKL18tKBk8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # Import the pandas library\n",
        "# create test csv\n",
        "def pad4(i):\n",
        "    return \"0\"*(4-len(str(i)))+str(i)\n",
        "df = pd.DataFrame()\n",
        "df[\"Id\"] = [pad4(i) for i in range(len(test_set))]\n",
        "df[\"Category\"] = prediction\n",
        "df.to_csv(\"submission.csv\",index = False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 7569409,
          "sourceId": 12030518,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 7573539,
          "sourceId": 12036177,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31041,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
